{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f7ac41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6057c244",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/appartements-data-db.csv')\n",
    "df.info()\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b239162",
   "metadata": {},
   "outputs": [],
   "source": [
    "#statistiques descriptives\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7f56db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# valeurs manquantes\n",
    "missing = df.isnull().sum()\n",
    "print(\"les valeurs manquantes : \\n\", missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a71383c",
   "metadata": {},
   "outputs": [],
   "source": [
    "doublons= df.duplicated()\n",
    "print(f\"Nombre de doublons : {doublons.sum()}\")\n",
    "print(f\"Nombre de lignes : {df[doublons==True]}\")\n",
    "df=df.drop_duplicates()\n",
    "doublons= df.duplicated()\n",
    "print(f\"Nombre de doublons : {doublons.sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7dbfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyser la distribution des variables numériques.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74bb41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Étudier les relations entre variables à l’aide de matrices de corrélation et de visualisations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753b55fb",
   "metadata": {},
   "source": [
    "# Prétraitement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c9bd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe0a52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,9))\n",
    "sns.heatmap(df.isnull())\n",
    "plt.savefig(\"../eda_img/df_null_values.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a106750",
   "metadata": {},
   "source": [
    "**Nettoyage & Transformation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b63defc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extraire les équipements (equipment) dans des colonnes booléennes à l’aide de str.get_dummies().\n",
    "if 'equipment' in df.columns : \n",
    "    equip=df[\"equipment\"].str.get_dummies(sep='/')\n",
    "    df= pd.concat([df.drop(\"equipment\",axis=1),equip],axis=1)\n",
    "print(\"colone avant 9 -> colonnes apres \", df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c12191",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad17031",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertir la colonne price (de type objet) en type float, en supprimant les caractères non numériques.\n",
    "df[\"price\"]= df[\"price\"].str.replace(r'[^\\d.]', '', regex=True).astype(float)\n",
    "df[\"price\"].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5808fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Supprimer les colonnes inutiles telles que equipment et link.\n",
    "df=df.drop(\"link\", axis=1)\n",
    "df.head(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f18e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Traitement de la colonne city_name. Uniformiser les noms de villes : convertir les noms en arabe vers leur équivalent français\n",
    "arabic_to_french = {\n",
    "    \"الدار البيضاء\": \"Casablanca\",\n",
    "    \"دار بوعزة\": \"Dar Bouazza\",\n",
    "    \"الرباط\": \"Rabat\",\n",
    "    \"مراكش\": \"Marrakech\",\n",
    "    \"أصيلة\": \"Asilah\",\n",
    "    \"بوسكورة\": \"Bouskoura\",\n",
    "    \"القنيطرة\": \"Kénitra\",\n",
    "    \"المحمدية\": \"Mohammedia\",\n",
    "    \"أكادير\": \"Agadir\",\n",
    "    \"تمارة الجديدة\": \"Tamesna\",\n",
    "    \"سلا\": \"Salé\",\n",
    "    \"حد سوالم\": \"Had Soualem\",\n",
    "    \"تمارة\": \"Temara\",\n",
    "    \"بن سليمان\": \"Benslimane\",\n",
    "    \"طنجة\": \"Tanger\",\n",
    "    \"بوزنيقة\": \"Bouznika\",\n",
    "    \"مكناس\": \"Meknès\",\n",
    "    \"فاس\": \"Fès\",\n",
    "    \"الجديدة\": \"El Jadida\",\n",
    "    \"المنصورية\": \"El Mansouria\",\n",
    "    \"مرتيل\": \"Martil\",\n",
    "    \"الفنيدق\": \"Fnideq\",\n",
    "    \"تطوان\": \"Tétouan\",\n",
    "    \"السعيدية\": \"Saidia\",\n",
    "    \"النواصر\": \"Nouaceur\",\n",
    "    \"تماريس\": \"Tamaris\",\n",
    "    \"كابو نيكرو\": \"Cabo Negro\",\n",
    "    \"سيدي علال البحراوي\": \"Sidi Allal El Bahraoui\",\n",
    "    \"بني ملال\": \"Béni Mellal\",\n",
    "    \"غير معروف\": \"Unknown\",\n",
    "    \"الصويرة\": \"Essaouira\",\n",
    "    \"المهدية\": \"Mehdia\",\n",
    "    \"وجدة\": \"Oujda\",\n",
    "    \"وادي لاو\": \"Oued Laou\",\n",
    "    \"الدشيرة\": \"Dcheira\",\n",
    "    \"سيدي رحال\": \"Sidi Rahal\",\n",
    "    \"دروة\": \"Deroua\",\n",
    "    \"عين عتيق\": \"Ain Attig\",\n",
    "    \"آسفي\": \"Safi\",\n",
    "    \"إنزكان\": \"Inzegan\",\n",
    "    \"إفران\": \"Ifrane\",\n",
    "    \"الداخلة\": \"Dakhla\",\n",
    "    \"الدشيرة الجهادية\": \"Dcheïra El Jihadia\",\n",
    "    \"تغازوت\": \"Taghazout\",\n",
    "    \"سيدي بوكنادل\": \"Sidi Bouknadel\",\n",
    "    \"الصخيرات\": \"Skhirat\",\n",
    "    \"خريبكة\": \"Khouribga\",\n",
    "    \"بركان\": \"Berkane\",\n",
    "    \"مرس الخير\": \"Mers El Kheir\",\n",
    "    \"برشيد\": \"Berrechid\",\n",
    "    \"تيزنيت\": \"Tiznit\",\n",
    "    \"أكادير ملول\": \"Agadir Melloul\",\n",
    "    \"الناظور\": \"Nador\",\n",
    "    \"المنزه\": \"El Menzeh\",\n",
    "    \"بني أنصار\": \"Bni Ansar\",\n",
    "    \"المضيق\": \"Mdiq\",\n",
    "    \"تيط مليل\": \"Tit Mellil\",\n",
    "    \"سوق أربعاء\": \"Souk El Arbaa\",\n",
    "    \"بيوڭرى\": \"Biougra\",\n",
    "    \"سطات\": \"Settat\",\n",
    "    \"عين عودة\": \"Ain Aouda\",\n",
    "    \"تازة\": \"Taza\",\n",
    "    \"الخميسات\": \"Khemisset\",\n",
    "    \"وادي زم\": \"Oued Zem\",\n",
    "    \"صفرو\": \"Sefrou\",\n",
    "    \"مرزوكة\": \"Merzouga\",\n",
    "    \"الحاجب\": \"El Hajeb\",\n",
    "    \"سلوان\": \"Selouane\",\n",
    "    \"تاونات\": \"Taounate\",\n",
    "    \"سيدي بنور\": \"Sidi Bennour\",\n",
    "    \"القصيبة\": \"El Ksiba\"\n",
    "}\n",
    "df[\"city_name\"]= df[\"city_name\"].replace(arabic_to_french)\n",
    "# Remplacer les valeurs manquantes dans city_name par \"Unknown\".\n",
    "df[\"city_name\"]= df[\"city_name\"].fillna(\"Unknown\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8d4f53",
   "metadata": {},
   "source": [
    "**Gestion des valeurs manquantes:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9b1ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extraire les colonnes num et categoroes\n",
    "col_num= df.select_dtypes(include=['float64']).columns\n",
    "col_cat= df.select_dtypes(include=[\"object\"]).columns\n",
    "print(\"col num: \\n\", col_num.tolist())\n",
    "print(\"col cat: \\n\", col_cat.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c5be0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "perce_null=df[col_num].isnull().sum() / df.shape[0] * 100\n",
    "print(\"les valeurs manquantes :\\n\",perce_null )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92d091b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pour les colonnes numériques : imputer les valeurs manquantes par la médiane.\n",
    "for col in col_num : \n",
    "    df[col]=df[col].fillna(df[col].median())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fd7949",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pour les colonnes catégorielles (chaînes de caractères) : imputer avec \"Unknown\"\n",
    "for col in col_cat : \n",
    "    df[col]=df[col].fillna(\"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7db0230",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33f7711",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,9))\n",
    "sns.heatmap(df.isnull())\n",
    "plt.savefig(\"../eda_img/df_after_hundel_null.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae650631",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57090ff",
   "metadata": {},
   "source": [
    "**Détection et suppression des valeurs aberrantes:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bc83c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utiliser des méthodes statistiques (boîtes à moustaches, z-score, IQR) pour détecter les outliers.\n",
    "# Supprimer les lignes contenant des valeurs aberrantes sur des colonnes clés (ex: price, surface_area, etc.).\n",
    "\n",
    "def find_remove_outliers(dataframe, column):\n",
    "  \n",
    "    Q1 = dataframe[column].quantile(0.25)\n",
    "    Q3 = dataframe[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    min_val = Q1 - 1.5 * IQR\n",
    "    max_val = Q3 + 1.5 * IQR\n",
    "\n",
    "    initial_rows = len(dataframe)\n",
    "    outliers_condition = (dataframe[column] < min_val) | (dataframe[column] > max_val)\n",
    "    print(f\"Nombre de valeurs aberrantes détectées dans '{column}': {outliers_condition.sum()}\")\n",
    "\n",
    "    df_cleaned = dataframe[~outliers_condition]\n",
    "    print(f\"{initial_rows - len(df_cleaned)} lignes ont été supprimées.\")\n",
    "\n",
    "    return df_cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56dc612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appliquer la fonction sur les colonnes clés\n",
    "df_cleaned = find_remove_outliers(df.copy(), 'price')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61428f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = find_remove_outliers(df_cleaned, 'nb_rooms')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08f5912",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = find_remove_outliers(df_cleaned, \"nb_baths\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d4880f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = find_remove_outliers(df_cleaned, 'surface_area')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7318e3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned=find_remove_outliers(df_cleaned,\"salon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5871f667",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"salon\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2a25ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nDimensions du DataFrame avant suppression des outliers : {df.shape}\")\n",
    "print(f\"Dimensions du DataFrame après suppression des outliers : {df_cleaned.shape}\")\n",
    "\n",
    "df = df_cleaned # Remplacer le df original par le df nettoyé"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820e164e",
   "metadata": {},
   "source": [
    "**Encodage des variables catégorielles:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8957ce7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Appliquer un Label Encoding selon le modèle utilisé, en particulier sur city_name.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "df[\"city_name\"]=encoder.fit_transform(df[\"city_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b20022",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"city_name\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b446b96",
   "metadata": {},
   "source": [
    "**Mise à l’échelle des variables:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439f760f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appliquer une normalisation (MinMaxScaler) ou une standardisation (StandardScaler) sur les variables numériques pour harmoniser les échelles.\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "numeric_features_for_scaling = col_num.drop('price') # Exclure la cible\n",
    "scaler = MinMaxScaler()\n",
    "df[numeric_features_for_scaling] = scaler.fit_transform(df[numeric_features_for_scaling])\n",
    "print(\"\\nDataFrame après encodage et mise à l'échelle :\")\n",
    "print(df[col_num])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a5117c",
   "metadata": {},
   "source": [
    "**Sélection des variables explicatives:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b643dee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choisir les variables numériques corrélées au prix (corr > 0.15).\n",
    "matrice_de_correlation = df.corr(numeric_only=True)\n",
    "price_correlation = matrice_de_correlation['price'].abs().sort_values(ascending=False)\n",
    "print(\"\\nCorrélation des variables avec le prix :\")\n",
    "print(price_correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f4b4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélectionner les variables avec une corrélation > 0.15 (sauf le prix lui-même)\n",
    "features = price_correlation[price_correlation > 0.15].index.drop('price').tolist()\n",
    "print(f\"\\nVariables sélectionnées pour le modèle : \\n{features}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f53d6e",
   "metadata": {},
   "source": [
    "**Séparation des données:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6744fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir la variable cible y = df[\"price\"].\n",
    "from sklearn.model_selection import train_test_split\n",
    "Y = df[\"price\"]\n",
    "# Définir les variables explicatives X à partir des colonnes sélectionnées.\n",
    "X=df[features]\n",
    "#  Diviser les données en ensemble d’entraînement et de test (80% / 20%) avec train_test_split.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"\\nTaille de l'ensemble d'entraînement : {X_train.shape}\")\n",
    "print(f\"Taille de l'ensemble de test : {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1290fcba",
   "metadata": {},
   "source": [
    "# Entraînement des modèles de régression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a29119c",
   "metadata": {},
   "source": [
    "**Entraîner plusieurs modèles :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fa8fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "import joblib # Pour sauvegarder le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567d346b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entraîner plusieurs modèles :\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Random Forest\": RandomForestRegressor(random_state=42),\n",
    "    \"SVR\": SVR(),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(random_state=42)\n",
    "}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    print(f\"✅ {name} entraîné avec succès.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f21461c",
   "metadata": {},
   "source": [
    "\n",
    "**Évaluer les modèles à l’aide de métriques adaptées à la régression :**\n",
    "\n",
    "MSE (Mean Squared Error) / RMSE (Root Mean Squared Error) / MAE (Mean Absolute Error) / R² Score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe295912",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    results[name] = {'RMSE': rmse, 'R2 Score': r2}\n",
    "    print(f\"--- {name} ---\")\n",
    "    print(f\"RMSE: {rmse:.2f}\")\n",
    "    print(f\"R² Score: {r2:.2f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a7052f",
   "metadata": {},
   "source": [
    "**Validation croisée:**\n",
    "\n",
    "Utiliser la validation croisée (cross-validation) pour évaluer la robustesse des modèles sur différentes portions du jeu de données.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079a027b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration de la validation croisée : K-Fold 5 plis avec mélange et seed fixe\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Dictionnaire pour stocker les scores moyens\n",
    "cv_results = {}\n",
    "\n",
    "# Boucle sur chaque modèle pour calculer le score R² moyen en validation croisée\n",
    "for name, model in models.items():\n",
    "    # Calcul des scores R² sur les 5 plis\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='r2')\n",
    "    \n",
    "    # Calcul de la moyenne des scores\n",
    "    mean_score = np.mean(scores)\n",
    "    \n",
    "    # Sauvegarde du score moyen\n",
    "    cv_results[name] = mean_score\n",
    "    \n",
    "    # Affichage clair du résultat\n",
    "    print(f\"{name} — R² moyen CV : {mean_score:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878817f3",
   "metadata": {},
   "source": [
    "**Optimisation des hyperparamètres:**\n",
    "\n",
    "Utiliser GridSearchCV ou RandomizedSearchCV pour rechercher les meilleurs hyperparamètres pour chaque modèle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94dd70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# 1. Définir les grilles d'hyperparamètres\n",
    "param_grids = {\n",
    "    \"Random Forest\": {\n",
    "        \"n_estimators\": [100, 200, 400],\n",
    "        \"max_depth\": [None, 10, 20],\n",
    "        \"min_samples_split\": [2, 5]\n",
    "    },\n",
    "    \"SVR\": {\n",
    "        \"C\": [0.1, 1, 10, 100],\n",
    "        \"gamma\": ['scale', 'auto'],\n",
    "        \"kernel\": ['rbf', 'linear']\n",
    "    }\n",
    "}\n",
    "\n",
    "# # 2. Exemple pour Random Forest avec GridSearchCV\n",
    "# rf = RandomForestRegressor(random_state=42)\n",
    "# grid_search_rf = GridSearchCV(\n",
    "#     estimator=rf,\n",
    "#     param_grid=param_grids[\"Random Forest\"],\n",
    "#     scoring='neg_mean_squared_error',   # Minimiser l'erreur quadratique moyenne\n",
    "#     cv=5,\n",
    "#     n_jobs=-1,\n",
    "#     verbose=1\n",
    "# )\n",
    "# grid_search_rf.fit(X_train, y_train)\n",
    "# print(\"Meilleurs paramètres RF :\", grid_search_rf.best_params_)\n",
    "\n",
    "# 3. Exemple pour SVR avec RandomizedSearchCV (plus rapide quand grille grande)\n",
    "svr = SVR()\n",
    "random_search_svr = RandomizedSearchCV(\n",
    "    estimator=svr,\n",
    "    param_distributions=param_grids[\"SVR\"],\n",
    "    n_iter=10,                         # nombre d'itérations aléatoires\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "random_search_svr.fit(X_train, y_train)\n",
    "print(\"Meilleurs paramètres SVR :\", random_search_svr.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcf6fac",
   "metadata": {},
   "source": [
    "**Sélection du meilleur modèle :**\n",
    "\n",
    "Comparer les performances des modèles et sélectionner celui avec les meilleurs scores (ex: R² élevé, RMSE faible).\n",
    "\n",
    "Sauvegarder le modèle entraîné (model.pkl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b942bf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionnaire pour stocker résultats de chaque modèle\n",
    "results = {}\n",
    "\n",
    "# Entraîner et évaluer chaque modèle\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)               # entraînement\n",
    "    y_pred = model.predict(X_test)            # prédiction\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))  # calcul RMSE\n",
    "    results[name] = {'model': model, 'RMSE': rmse}\n",
    "\n",
    "# Trouver le meilleur modèle (celui avec le RMSE le plus faible)\n",
    "best_model_name = min(results, key=lambda k: results[k]['RMSE'])\n",
    "best_model = results[best_model_name]['model']\n",
    "best_rmse = results[best_model_name]['RMSE']\n",
    "\n",
    "print(f\"✅ Meilleur modèle : {best_model_name} avec RMSE = {best_rmse:.2f}\")\n",
    "\n",
    "# Sauvegarder le meilleur modèle dans un fichier .pkl\n",
    "joblib.dump(best_model, '../models/model.pkl')\n",
    "print(\"Modèle sauvegardé sous 'model.pkl'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
